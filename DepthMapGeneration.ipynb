{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DepthMapGeneration.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "961e7352689d41a5af1fdd08e741522b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_197de06c8e2f423e91a2df082ae5b300",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_057bb7cb1bbe4da2bdccf38ea6b64845",
              "IPY_MODEL_b28a8f7e590a472d9dff8f2f6c6c7749"
            ]
          }
        },
        "197de06c8e2f423e91a2df082ae5b300": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "057bb7cb1bbe4da2bdccf38ea6b64845": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_96281b43d43d4bafa4240d74fdba10e3",
            "_dom_classes": [],
            "description": " 10%",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 100,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 10,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_51ff55c8f8484de7bd9fe6e406a411fa"
          }
        },
        "b28a8f7e590a472d9dff8f2f6c6c7749": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_59b4f2c2dddd4d43acd9f3255486e539",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 10/100 [1:15:28&lt;11:35:20, 463.57s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f20aa1ca378c49fc997cd0e55ffb4d0c"
          }
        },
        "96281b43d43d4bafa4240d74fdba10e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "51ff55c8f8484de7bd9fe6e406a411fa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "59b4f2c2dddd4d43acd9f3255486e539": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f20aa1ca378c49fc997cd0e55ffb4d0c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8d4759b0cfe84fc59b746ac19c33c0a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_4c4b4eadad2e457bb2e6a7e15a185104",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_d756f1a8edf04c77b54ea907f08d0a4b",
              "IPY_MODEL_80f311110e84407fb5195617bed1449d"
            ]
          }
        },
        "4c4b4eadad2e457bb2e6a7e15a185104": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d756f1a8edf04c77b54ea907f08d0a4b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_9ada3a3d9c94485d89dafd54673f35e3",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 90,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 90,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2b4c71ab95ec429fa9293930ddbbcf82"
          }
        },
        "80f311110e84407fb5195617bed1449d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_dd564d05f63646beb2e2c55d09915fd7",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 90/90 [3:16:56&lt;00:00, 131.29s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6e01092ba49b4bddaa13208387410476"
          }
        },
        "9ada3a3d9c94485d89dafd54673f35e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2b4c71ab95ec429fa9293930ddbbcf82": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "dd564d05f63646beb2e2c55d09915fd7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6e01092ba49b4bddaa13208387410476": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EJQAT2j6toWD",
        "colab_type": "text"
      },
      "source": [
        "# Generate Depth Map\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FTg6gR474c0K",
        "colab_type": "code",
        "outputId": "c1a3a40c-e1e5-45be-ae19-3b6005375935",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import torch\n",
        "from IPython.display import Image, clear_output \n",
        "print('PyTorch %s %s' % (torch.__version__, torch.cuda.get_device_properties(0) if torch.cuda.is_available() else 'CPU'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "PyTorch 1.5.0+cu101 _CudaDeviceProperties(name='Tesla P100-PCIE-16GB', major=6, minor=0, total_memory=16280MB, multi_processor_count=56)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w6W75MQgsrYt",
        "colab_type": "code",
        "outputId": "e5279e89-e907-4b2d-ac4e-362ddbe6847d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HEM72GAWtxNh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git clone https://github.com/genigarus/DenseDepth.git"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Din8EeG9yqnv",
        "colab_type": "code",
        "outputId": "6c08caeb-d16f-4b02-b628-17c8bc9e7fb8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from PIL import Image\n",
        "from io import BytesIO\n",
        "\n",
        "def load_zip_images(image_files):\n",
        "    loaded_images = []\n",
        "    for file in image_files:\n",
        "        x = np.clip(np.asarray(Image.open(BytesIO(data[ file ])), dtype=float) / 255, 0, 1)\n",
        "        loaded_images.append(x)\n",
        "    return np.stack(loaded_images, axis=0)\n",
        "\n",
        "def loadZipToMem(zip_file):\n",
        "    # Load zip file into memory\n",
        "    print('Loading dataset zip file...', end='')\n",
        "    from zipfile import ZipFile\n",
        "    input_zip = ZipFile(zip_file, 'r')\n",
        "    data = {name: input_zip.read(name) for name in input_zip.namelist()}\n",
        "    input_zip.close()\n",
        "    \n",
        "    return data\n",
        "\n",
        "def save_zip_images(filename, outputs):\n",
        "    image = outputs.reshape(outputs.shape[0],outputs.shape[1])\n",
        "    fig = plt.figure(figsize=(1.60, 1.60))\n",
        "    ax = plt.Axes(fig, [0., 0., 1., 1.])\n",
        "    ax.set_axis_off()\n",
        "    fig.add_axes(ax)\n",
        "    ax.imshow(image, aspect='equal')\n",
        "    plt.savefig(filename, dpi=100)\n",
        "    ax.cla()\n",
        "    ax.clear()\n",
        "    plt.close(fig)\n",
        "\n",
        "data = loadZipToMem('./gdrive/My Drive/EVA4/DepthMaskDataset/depth_mask_custom_dataset.zip')\n",
        "\n",
        "custom_data = list((row.split('\\t') for row in (data['data_label.txt']).decode(\"utf-8\").split('\\n') if len(row) > 0))\n",
        "fg_bg_list = []\n",
        "for fg_bg_img_row in custom_data:\n",
        "  fg_bg_list.append(fg_bg_img_row[0])\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading dataset zip file..."
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s9vbgcgRt7dH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.chdir('./DenseDepth')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3dL_0HPBkHxJ",
        "colab_type": "code",
        "outputId": "3a244903-36b8-4ebc-8a20-2fd41d9e50d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!mkdir NYU/weights"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory â€˜NYU/weightsâ€™: File exists\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qrzrjTlZkOEV",
        "colab_type": "code",
        "outputId": "67ed645d-cfa4-436a-d3a0-897a11088a4c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "!wget https://s3-eu-west-1.amazonaws.com/densedepth/nyu.h5 -O ./NYU/weights/nyu.h5  #0.01GB"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-05-10 15:44:54--  https://s3-eu-west-1.amazonaws.com/densedepth/nyu.h5\n",
            "Resolving s3-eu-west-1.amazonaws.com (s3-eu-west-1.amazonaws.com)... 52.218.84.74\n",
            "Connecting to s3-eu-west-1.amazonaws.com (s3-eu-west-1.amazonaws.com)|52.218.84.74|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 172897376 (165M) [application/h5]\n",
            "Saving to: â€˜./NYU/weights/nyu.h5â€™\n",
            "\n",
            "./NYU/weights/nyu.h 100%[===================>] 164.89M  22.6MB/s    in 8.3s    \n",
            "\n",
            "2020-05-10 15:45:03 (19.8 MB/s) - â€˜./NYU/weights/nyu.h5â€™ saved [172897376/172897376]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mtQombPtkUsh",
        "colab_type": "code",
        "outputId": "d272353e-88d8-46cb-9154-2b5dda6747cd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import math, random, glob, os\n",
        "# from random import random\n",
        "# from random import seed\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "from CreateDepthMaskNYU import CreateDepthMaskNYU\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "\n",
        "import zipfile\n",
        "import gc"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OJGw1q55kbnt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_path = r'./NYU/weights/nyu.h5'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D8cO1W871Y3A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import glob\n",
        "import os, time\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import NYU\n",
        "from NYU import BilinearUpSampling2D, predict, scale_up, display_images, load_images\n",
        "\n",
        "\n",
        "class CreateDepthMask:\n",
        "\n",
        "    def __init__(self, model_path):\n",
        "        self.model = None\n",
        "\n",
        "        if os.path.isfile(model_path):\n",
        "            print('Loading model...')\n",
        "\n",
        "            # Custom object needed for inference and training\n",
        "            custom_objects = {'BilinearUpSampling2D': BilinearUpSampling2D, 'depth_loss_function': None}\n",
        "\n",
        "            # Load model into GPU / CPU\n",
        "            self.model = NYU.load_model(model_path, custom_objects=custom_objects, compile=False)\n",
        "\n",
        "            print('\\nModel loaded ({0}).'.format(model_path))\n",
        "\n",
        "    def get_depth_map_from_zip(self, image_list, scale, batch_size=1):\n",
        "\n",
        "        if self.model is not None:\n",
        "            # Input images\n",
        "            t1 = time.time()\n",
        "            inputs = load_zip_images(image_list)\n",
        "            t2 = time.time()\n",
        "            print(f'\\nLoaded ({inputs.shape[0]}) images of size {inputs.shape[1:]} in {t2-t1} sec.')\n",
        "\n",
        "            if scale > 1:\n",
        "                inputs = scale_up(scale, inputs)\n",
        "\n",
        "            # Compute results\n",
        "            t1 = time.time()\n",
        "            outputs = predict(self.model, inputs, batch_size)\n",
        "            t2 = time.time()\n",
        "            print(f'Actual prediction time: {t2-t1} sec.')\n",
        "            return outputs\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DDJJa4COkgQ3",
        "colab_type": "code",
        "outputId": "069b1192-33ae-44cf-d7bf-b2a952d2a149",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "depth_model = CreateDepthMask(model_path) #0.72GB"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading model...\n",
            "\n",
            "Model loaded (./NYU/weights/nyu.h5).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "flIPvvhftudj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.chdir('../gdrive/My Drive/EVA4/DepthMaskDataset')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ohRtOXUBR7L",
        "colab_type": "code",
        "outputId": "443ebd3f-bfe9-482a-ba42-ec9b40383abd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "961e7352689d41a5af1fdd08e741522b",
            "197de06c8e2f423e91a2df082ae5b300",
            "057bb7cb1bbe4da2bdccf38ea6b64845",
            "b28a8f7e590a472d9dff8f2f6c6c7749",
            "96281b43d43d4bafa4240d74fdba10e3",
            "51ff55c8f8484de7bd9fe6e406a411fa",
            "59b4f2c2dddd4d43acd9f3255486e539",
            "f20aa1ca378c49fc997cd0e55ffb4d0c"
          ]
        }
      },
      "source": [
        "import zipfile\n",
        "import gc\n",
        "import numpy as np\n",
        "\n",
        "zip_file_name = \"DepthMapData.zip\"\n",
        "bs = 200*20\n",
        "batch_size = 32\n",
        "for i in tqdm(range(0, 100)):\n",
        "  print(f\"\\nIteration{i+1}\")\n",
        "\n",
        "  # Input images\n",
        "  print(\"Predicting....\")\n",
        "  outputs = depth_model.get_depth_map_from_zip(fg_bg_list[bs*i: (bs*i)+bs], 1, batch_size)\n",
        "\n",
        "  print(\"Saving...\")\n",
        "  zf1 = zipfile.ZipFile(zip_file_name, mode='a', compression=zipfile.ZIP_STORED)\n",
        "  label_info = open('data_label.txt', 'a+')\n",
        "  for itr in range(outputs.shape[0]):\n",
        "    filename = f\"/{fg_bg_list[(bs*i)+itr].split('/')[-1].split('.')[0]}_depthmap_{fg_bg_list[(bs*i)+itr].split('/')[-1].split('.')[0].split('_')[-1]}.jpg\"\n",
        "    label_info.write(f'Batch {i}\\tdata/fg_bg_depth_map/batch_{i:03d}/{filename}\\n')\n",
        "    save_zip_images(\"depth_map.jpg\", outputs[itr])\n",
        "    zf1.write(\"depth_map.jpg\", f'data/fg_bg_depth_map/batch_{i:03d}/{filename}')\n",
        "  label_info.close()\n",
        "  zf1.close()\n",
        "\n",
        "  np.savez_compressed(f'data/fg_bg_depth/depthmap_output_batch{i+1}.npz', output=outputs)\n",
        "\n",
        "  del outputs\n",
        "  del label_info\n",
        "  del zf1\n",
        "  gc.collect()\n",
        "  \n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "961e7352689d41a5af1fdd08e741522b",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Iteration1\n",
            "Predicting....\n",
            "\n",
            "Loaded (inputs.shape[0]) images of size (160, 160, 3) in 12.75155234336853 sec.\n",
            "Actual prediction time: 120.39214968681335 sec.\n",
            "Saving...\n",
            "\n",
            "Iteration2\n",
            "Predicting....\n",
            "\n",
            "Loaded (inputs.shape[0]) images of size (160, 160, 3) in 11.079334020614624 sec.\n",
            "Actual prediction time: 102.04290843009949 sec.\n",
            "Saving...\n",
            "\n",
            "Iteration3\n",
            "Predicting....\n",
            "\n",
            "Loaded (inputs.shape[0]) images of size (160, 160, 3) in 13.701427698135376 sec.\n",
            "Actual prediction time: 101.24023127555847 sec.\n",
            "Saving...\n",
            "\n",
            "Iteration4\n",
            "Predicting....\n",
            "\n",
            "Loaded (inputs.shape[0]) images of size (160, 160, 3) in 9.89923357963562 sec.\n",
            "Actual prediction time: 102.24694514274597 sec.\n",
            "Saving...\n",
            "\n",
            "Iteration5\n",
            "Predicting....\n",
            "\n",
            "Loaded (inputs.shape[0]) images of size (160, 160, 3) in 9.71603536605835 sec.\n",
            "Actual prediction time: 101.81047201156616 sec.\n",
            "Saving...\n",
            "\n",
            "Iteration6\n",
            "Predicting....\n",
            "\n",
            "Loaded (inputs.shape[0]) images of size (160, 160, 3) in 12.5301513671875 sec.\n",
            "Actual prediction time: 100.87504434585571 sec.\n",
            "Saving...\n",
            "\n",
            "Iteration7\n",
            "Predicting....\n",
            "\n",
            "Loaded (inputs.shape[0]) images of size (160, 160, 3) in 13.915613174438477 sec.\n",
            "Actual prediction time: 101.90817594528198 sec.\n",
            "Saving...\n",
            "\n",
            "Iteration8\n",
            "Predicting....\n",
            "\n",
            "Loaded (inputs.shape[0]) images of size (160, 160, 3) in 10.138357639312744 sec.\n",
            "Actual prediction time: 101.96311688423157 sec.\n",
            "Saving...\n",
            "\n",
            "Iteration9\n",
            "Predicting....\n",
            "\n",
            "Loaded (inputs.shape[0]) images of size (160, 160, 3) in 12.307630062103271 sec.\n",
            "Actual prediction time: 102.6949553489685 sec.\n",
            "Saving...\n",
            "\n",
            "Iteration10\n",
            "Predicting....\n",
            "\n",
            "Loaded (inputs.shape[0]) images of size (160, 160, 3) in 17.46599793434143 sec.\n",
            "Actual prediction time: 102.65200805664062 sec.\n",
            "Saving...\n",
            "\n",
            "Iteration11\n",
            "Predicting....\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-X_B8IhBjG2x",
        "colab_type": "code",
        "outputId": "5eb455a6-b44c-429c-a12d-d86f73c07f9b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "8d4759b0cfe84fc59b746ac19c33c0a6",
            "4c4b4eadad2e457bb2e6a7e15a185104",
            "d756f1a8edf04c77b54ea907f08d0a4b",
            "80f311110e84407fb5195617bed1449d",
            "9ada3a3d9c94485d89dafd54673f35e3",
            "2b4c71ab95ec429fa9293930ddbbcf82",
            "dd564d05f63646beb2e2c55d09915fd7",
            "6e01092ba49b4bddaa13208387410476"
          ]
        }
      },
      "source": [
        "import zipfile\n",
        "import gc\n",
        "import numpy as np\n",
        "\n",
        "#zip_file_name = \"DepthMapData.zip\"\n",
        "bs = 200*20\n",
        "batch_size = 32\n",
        "for i in tqdm(range(10, 100)):\n",
        "  print(f\"\\nIteration{i+1} - Images [{bs*i}: {(bs*i)+bs}]\")\n",
        "\n",
        "  # Input images\n",
        "  print(\"Predicting....\")\n",
        "  outputs = depth_model.get_depth_map_from_zip(fg_bg_list[bs*i: (bs*i)+bs], 1, batch_size)\n",
        "\n",
        "  print(\"Saving...\")\n",
        "  zf1 = zipfile.ZipFile(zip_file_name, mode='a', compression=zipfile.ZIP_STORED)\n",
        "  label_info = open('data_label.txt', 'a+')\n",
        "  for itr in range(outputs.shape[0]):\n",
        "    filename = f\"/{fg_bg_list[(bs*i)+itr].split('/')[-1].split('.')[0]}_depthmap_{fg_bg_list[(bs*i)+itr].split('/')[-1].split('.')[0].split('_')[-1]}.jpg\"\n",
        "    label_info.write(f'Batch {i}\\tdata/fg_bg_depth_map/batch_{i:03d}/{filename}\\n')\n",
        "    save_zip_images(\"depth_map.jpg\", outputs[itr])\n",
        "    zf1.write(\"depth_map.jpg\", f'data/fg_bg_depth_map/batch_{i:03d}/{filename}')\n",
        "  label_info.close()\n",
        "  zf1.close()\n",
        "\n",
        "  np.savez_compressed(f'data/fg_bg_depth/depthmap_output_batch{i+1}.npz', output=outputs)\n",
        "\n",
        "  del outputs\n",
        "  del label_info\n",
        "  del zf1\n",
        "  gc.collect()\n",
        "  \n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8d4759b0cfe84fc59b746ac19c33c0a6",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=90.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Iteration11 - Images [40000: 44000]\n",
            "Predicting....\n",
            "\n",
            "Loaded (4000) images of size (160, 160, 3) in 13.600987672805786 sec.\n",
            "Actual prediction time: 133.02228021621704 sec.\n",
            "Saving...\n",
            "\n",
            "Iteration12 - Images [44000: 48000]\n",
            "Predicting....\n",
            "\n",
            "Loaded (4000) images of size (160, 160, 3) in 10.473581075668335 sec.\n",
            "Actual prediction time: 115.40894675254822 sec.\n",
            "Saving...\n",
            "\n",
            "Iteration13 - Images [48000: 52000]\n",
            "Predicting....\n",
            "\n",
            "Loaded (4000) images of size (160, 160, 3) in 10.163222789764404 sec.\n",
            "Actual prediction time: 113.36479067802429 sec.\n",
            "Saving...\n",
            "\n",
            "Iteration14 - Images [52000: 56000]\n",
            "Predicting....\n",
            "\n",
            "Loaded (4000) images of size (160, 160, 3) in 9.976438045501709 sec.\n",
            "Actual prediction time: 113.50731253623962 sec.\n",
            "Saving...\n",
            "\n",
            "Iteration15 - Images [56000: 60000]\n",
            "Predicting....\n",
            "\n",
            "Loaded (4000) images of size (160, 160, 3) in 10.180702686309814 sec.\n",
            "Actual prediction time: 113.20022010803223 sec.\n",
            "Saving...\n",
            "\n",
            "Iteration16 - Images [60000: 64000]\n",
            "Predicting....\n",
            "\n",
            "Loaded (4000) images of size (160, 160, 3) in 10.047029495239258 sec.\n",
            "Actual prediction time: 113.78791213035583 sec.\n",
            "Saving...\n",
            "\n",
            "Iteration17 - Images [64000: 68000]\n",
            "Predicting....\n",
            "\n",
            "Loaded (4000) images of size (160, 160, 3) in 10.124678611755371 sec.\n",
            "Actual prediction time: 114.26956105232239 sec.\n",
            "Saving...\n",
            "\n",
            "Iteration18 - Images [68000: 72000]\n",
            "Predicting....\n",
            "\n",
            "Loaded (4000) images of size (160, 160, 3) in 10.175276279449463 sec.\n",
            "Actual prediction time: 113.35881805419922 sec.\n",
            "Saving...\n",
            "\n",
            "Iteration19 - Images [72000: 76000]\n",
            "Predicting....\n",
            "\n",
            "Loaded (4000) images of size (160, 160, 3) in 9.891202449798584 sec.\n",
            "Actual prediction time: 112.58094906806946 sec.\n",
            "Saving...\n",
            "\n",
            "Iteration20 - Images [76000: 80000]\n",
            "Predicting....\n",
            "\n",
            "Loaded (4000) images of size (160, 160, 3) in 10.061228275299072 sec.\n",
            "Actual prediction time: 112.95953869819641 sec.\n",
            "Saving...\n",
            "\n",
            "Iteration21 - Images [80000: 84000]\n",
            "Predicting....\n",
            "\n",
            "Loaded (4000) images of size (160, 160, 3) in 9.970139503479004 sec.\n",
            "Actual prediction time: 112.76215147972107 sec.\n",
            "Saving...\n",
            "\n",
            "Iteration22 - Images [84000: 88000]\n",
            "Predicting....\n",
            "\n",
            "Loaded (4000) images of size (160, 160, 3) in 9.958216428756714 sec.\n",
            "Actual prediction time: 111.9173834323883 sec.\n",
            "Saving...\n",
            "\n",
            "Iteration23 - Images [88000: 92000]\n",
            "Predicting....\n",
            "\n",
            "Loaded (4000) images of size (160, 160, 3) in 9.92534327507019 sec.\n",
            "Actual prediction time: 111.29058194160461 sec.\n",
            "Saving...\n",
            "\n",
            "Iteration24 - Images [92000: 96000]\n",
            "Predicting....\n",
            "\n",
            "Loaded (4000) images of size (160, 160, 3) in 10.090834856033325 sec.\n",
            "Actual prediction time: 112.89400005340576 sec.\n",
            "Saving...\n",
            "\n",
            "Iteration25 - Images [96000: 100000]\n",
            "Predicting....\n",
            "\n",
            "Loaded (4000) images of size (160, 160, 3) in 10.10343623161316 sec.\n",
            "Actual prediction time: 113.2150092124939 sec.\n",
            "Saving...\n",
            "\n",
            "Iteration26 - Images [100000: 104000]\n",
            "Predicting....\n",
            "\n",
            "Loaded (4000) images of size (160, 160, 3) in 10.014063596725464 sec.\n",
            "Actual prediction time: 112.83314251899719 sec.\n",
            "Saving...\n",
            "\n",
            "Iteration27 - Images [104000: 108000]\n",
            "Predicting....\n",
            "\n",
            "Loaded (4000) images of size (160, 160, 3) in 9.9481041431427 sec.\n",
            "Actual prediction time: 113.90177321434021 sec.\n",
            "Saving...\n",
            "\n",
            "Iteration28 - Images [108000: 112000]\n",
            "Predicting....\n",
            "\n",
            "Loaded (4000) images of size (160, 160, 3) in 10.104904413223267 sec.\n",
            "Actual prediction time: 113.00277853012085 sec.\n",
            "Saving...\n",
            "\n",
            "Iteration29 - Images [112000: 116000]\n",
            "Predicting....\n",
            "\n",
            "Loaded (4000) images of size (160, 160, 3) in 10.09501314163208 sec.\n",
            "Actual prediction time: 113.72908520698547 sec.\n",
            "Saving...\n",
            "\n",
            "Iteration30 - Images [116000: 120000]\n",
            "Predicting....\n",
            "\n",
            "Loaded (4000) images of size (160, 160, 3) in 10.016740798950195 sec.\n",
            "Actual prediction time: 113.175133228302 sec.\n",
            "Saving...\n",
            "\n",
            "Iteration31 - Images [120000: 124000]\n",
            "Predicting....\n",
            "\n",
            "Loaded (4000) images of size (160, 160, 3) in 10.179971933364868 sec.\n",
            "Actual prediction time: 113.36351418495178 sec.\n",
            "Saving...\n",
            "\n",
            "Iteration32 - Images [124000: 128000]\n",
            "Predicting....\n",
            "\n",
            "Loaded (4000) images of size (160, 160, 3) in 10.091226816177368 sec.\n",
            "Actual prediction time: 113.15798234939575 sec.\n",
            "Saving...\n",
            "\n",
            "Iteration33 - Images [128000: 132000]\n",
            "Predicting....\n",
            "\n",
            "Loaded (4000) images of size (160, 160, 3) in 10.2258939743042 sec.\n",
            "Actual prediction time: 112.16171312332153 sec.\n",
            "Saving...\n",
            "\n",
            "Iteration34 - Images [132000: 136000]\n",
            "Predicting....\n",
            "\n",
            "Loaded (4000) images of size (160, 160, 3) in 10.037371635437012 sec.\n",
            "Actual prediction time: 113.07292485237122 sec.\n",
            "Saving...\n",
            "\n",
            "Iteration35 - Images [136000: 140000]\n",
            "Predicting....\n",
            "\n",
            "Loaded (4000) images of size (160, 160, 3) in 10.213270902633667 sec.\n",
            "Actual prediction time: 112.60785126686096 sec.\n",
            "Saving...\n",
            "\n",
            "Iteration36 - Images [140000: 144000]\n",
            "Predicting....\n",
            "\n",
            "Loaded (4000) images of size (160, 160, 3) in 10.120361804962158 sec.\n",
            "Actual prediction time: 114.20291781425476 sec.\n",
            "Saving...\n",
            "\n",
            "Iteration37 - Images [144000: 148000]\n",
            "Predicting....\n",
            "\n",
            "Loaded (4000) images of size (160, 160, 3) in 10.070033311843872 sec.\n",
            "Actual prediction time: 113.30197334289551 sec.\n",
            "Saving...\n",
            "\n",
            "Iteration38 - Images [148000: 152000]\n",
            "Predicting....\n",
            "\n",
            "Loaded (4000) images of size (160, 160, 3) in 10.232242584228516 sec.\n",
            "Actual prediction time: 113.61153149604797 sec.\n",
            "Saving...\n",
            "\n",
            "Iteration39 - Images [152000: 156000]\n",
            "Predicting....\n",
            "\n",
            "Loaded (4000) images of size (160, 160, 3) in 10.23604440689087 sec.\n",
            "Actual prediction time: 114.1024079322815 sec.\n",
            "Saving...\n",
            "\n",
            "Iteration40 - Images [156000: 160000]\n",
            "Predicting....\n",
            "\n",
            "Loaded (4000) images of size (160, 160, 3) in 10.133250951766968 sec.\n",
            "Actual prediction time: 112.84442210197449 sec.\n",
            "Saving...\n",
            "\n",
            "Iteration41 - Images [160000: 164000]\n",
            "Predicting....\n",
            "\n",
            "Loaded (4000) images of size (160, 160, 3) in 9.941329956054688 sec.\n",
            "Actual prediction time: 111.98213338851929 sec.\n",
            "Saving...\n",
            "\n",
            "Iteration42 - Images [164000: 168000]\n",
            "Predicting....\n",
            "\n",
            "Loaded (4000) images of size (160, 160, 3) in 10.02314019203186 sec.\n",
            "Actual prediction time: 112.65962362289429 sec.\n",
            "Saving...\n",
            "\n",
            "Iteration43 - Images [168000: 172000]\n",
            "Predicting....\n",
            "\n",
            "Loaded (4000) images of size (160, 160, 3) in 10.314229011535645 sec.\n",
            "Actual prediction time: 114.02285385131836 sec.\n",
            "Saving...\n",
            "\n",
            "Iteration44 - Images [172000: 176000]\n",
            "Predicting....\n",
            "\n",
            "Loaded (4000) images of size (160, 160, 3) in 10.089550256729126 sec.\n",
            "Actual prediction time: 114.36064338684082 sec.\n",
            "Saving...\n",
            "\n",
            "Iteration45 - Images [176000: 180000]\n",
            "Predicting....\n",
            "\n",
            "Loaded (4000) images of size (160, 160, 3) in 10.448962211608887 sec.\n",
            "Actual prediction time: 113.27269530296326 sec.\n",
            "Saving...\n",
            "\n",
            "Iteration46 - Images [180000: 184000]\n",
            "Predicting....\n",
            "\n",
            "Loaded (4000) images of size (160, 160, 3) in 10.166628360748291 sec.\n",
            "Actual prediction time: 115.06782841682434 sec.\n",
            "Saving...\n",
            "\n",
            "Iteration47 - Images [184000: 188000]\n",
            "Predicting....\n",
            "\n",
            "Loaded (4000) images of size (160, 160, 3) in 10.147464990615845 sec.\n",
            "Actual prediction time: 114.66821026802063 sec.\n",
            "Saving...\n",
            "\n",
            "Iteration48 - Images [188000: 192000]\n",
            "Predicting....\n",
            "\n",
            "Loaded (4000) images of size (160, 160, 3) in 10.098196506500244 sec.\n",
            "Actual prediction time: 113.97006297111511 sec.\n",
            "Saving...\n",
            "\n",
            "Iteration49 - Images [192000: 196000]\n",
            "Predicting....\n",
            "\n",
            "Loaded (4000) images of size (160, 160, 3) in 10.284269571304321 sec.\n",
            "Actual prediction time: 115.84330606460571 sec.\n",
            "Saving...\n",
            "\n",
            "Iteration50 - Images [196000: 200000]\n",
            "Predicting....\n",
            "\n",
            "Loaded (4000) images of size (160, 160, 3) in 10.135273694992065 sec.\n",
            "Actual prediction time: 114.11078095436096 sec.\n",
            "Saving...\n",
            "\n",
            "Iteration51 - Images [200000: 204000]\n",
            "Predicting....\n",
            "\n",
            "Loaded (4000) images of size (160, 160, 3) in 9.949642419815063 sec.\n",
            "Actual prediction time: 113.82527875900269 sec.\n",
            "Saving...\n",
            "\n",
            "Iteration52 - Images [204000: 208000]\n",
            "Predicting....\n",
            "\n",
            "Loaded (4000) images of size (160, 160, 3) in 10.307199001312256 sec.\n",
            "Actual prediction time: 113.21322417259216 sec.\n",
            "Saving...\n",
            "\n",
            "Iteration53 - Images [208000: 212000]\n",
            "Predicting....\n",
            "\n",
            "Loaded (4000) images of size (160, 160, 3) in 10.143377542495728 sec.\n",
            "Actual prediction time: 114.16927313804626 sec.\n",
            "Saving...\n",
            "\n",
            "Iteration54 - Images [212000: 216000]\n",
            "Predicting....\n",
            "\n",
            "Loaded (4000) images of size (160, 160, 3) in 10.273847579956055 sec.\n",
            "Actual prediction time: 114.74731230735779 sec.\n",
            "Saving...\n",
            "\n",
            "Iteration55 - Images [216000: 220000]\n",
            "Predicting....\n",
            "\n",
            "Loaded (4000) images of size (160, 160, 3) in 10.645651578903198 sec.\n",
            "Actual prediction time: 115.11835861206055 sec.\n",
            "Saving...\n",
            "\n",
            "Iteration56 - Images [220000: 224000]\n",
            "Predicting....\n",
            "\n",
            "Loaded (4000) images of size (160, 160, 3) in 10.5112943649292 sec.\n",
            "Actual prediction time: 113.55182123184204 sec.\n",
            "Saving...\n",
            "\n",
            "Iteration57 - Images [224000: 228000]\n",
            "Predicting....\n",
            "\n",
            "Loaded (4000) images of size (160, 160, 3) in 10.729198455810547 sec.\n",
            "Actual prediction time: 113.85064911842346 sec.\n",
            "Saving...\n",
            "\n",
            "Iteration58 - Images [228000: 232000]\n",
            "Predicting....\n",
            "\n",
            "Loaded (4000) images of size (160, 160, 3) in 10.52165961265564 sec.\n",
            "Actual prediction time: 113.02223825454712 sec.\n",
            "Saving...\n",
            "\n",
            "Iteration59 - Images [232000: 236000]\n",
            "Predicting....\n",
            "\n",
            "Loaded (4000) images of size (160, 160, 3) in 10.452193260192871 sec.\n",
            "Actual prediction time: 113.86080145835876 sec.\n",
            "Saving...\n",
            "\n",
            "Iteration60 - Images [236000: 240000]\n",
            "Predicting....\n",
            "\n",
            "Loaded (4000) images of size (160, 160, 3) in 10.288711071014404 sec.\n",
            "Actual prediction time: 112.60814476013184 sec.\n",
            "Saving...\n",
            "\n",
            "Iteration61 - Images [240000: 244000]\n",
            "Predicting....\n",
            "\n",
            "Loaded (4000) images of size (160, 160, 3) in 10.36133885383606 sec.\n",
            "Actual prediction time: 112.37655806541443 sec.\n",
            "Saving...\n",
            "\n",
            "Iteration62 - Images [244000: 248000]\n",
            "Predicting....\n",
            "\n",
            "Loaded (4000) images of size (160, 160, 3) in 10.353551149368286 sec.\n",
            "Actual prediction time: 112.80510210990906 sec.\n",
            "Saving...\n",
            "\n",
            "Iteration63 - Images [248000: 252000]\n",
            "Predicting....\n",
            "\n",
            "Loaded (4000) images of size (160, 160, 3) in 10.351757764816284 sec.\n",
            "Actual prediction time: 113.4908356666565 sec.\n",
            "Saving...\n",
            "\n",
            "Iteration64 - Images [252000: 256000]\n",
            "Predicting....\n",
            "\n",
            "Loaded (4000) images of size (160, 160, 3) in 10.63912558555603 sec.\n",
            "Actual prediction time: 114.30081868171692 sec.\n",
            "Saving...\n",
            "\n",
            "Iteration65 - Images [256000: 260000]\n",
            "Predicting....\n",
            "\n",
            "Loaded (4000) images of size (160, 160, 3) in 10.537884712219238 sec.\n",
            "Actual prediction time: 113.2765440940857 sec.\n",
            "Saving...\n",
            "\n",
            "Iteration66 - Images [260000: 264000]\n",
            "Predicting....\n",
            "\n",
            "Loaded (4000) images of size (160, 160, 3) in 10.527080774307251 sec.\n",
            "Actual prediction time: 113.83314347267151 sec.\n",
            "Saving...\n",
            "\n",
            "Iteration67 - Images [264000: 268000]\n",
            "Predicting....\n",
            "\n",
            "Loaded (4000) images of size (160, 160, 3) in 10.27246379852295 sec.\n",
            "Actual prediction time: 112.75843858718872 sec.\n",
            "Saving...\n",
            "\n",
            "Iteration68 - Images [268000: 272000]\n",
            "Predicting....\n",
            "\n",
            "Loaded (4000) images of size (160, 160, 3) in 10.333091735839844 sec.\n",
            "Actual prediction time: 114.16231775283813 sec.\n",
            "Saving...\n",
            "\n",
            "Iteration69 - Images [272000: 276000]\n",
            "Predicting....\n",
            "\n",
            "Loaded (4000) images of size (160, 160, 3) in 10.191792488098145 sec.\n",
            "Actual prediction time: 113.9850378036499 sec.\n",
            "Saving...\n",
            "\n",
            "Iteration70 - Images [276000: 280000]\n",
            "Predicting....\n",
            "\n",
            "Loaded (4000) images of size (160, 160, 3) in 10.263331890106201 sec.\n",
            "Actual prediction time: 114.2086546421051 sec.\n",
            "Saving...\n",
            "\n",
            "Iteration71 - Images [280000: 284000]\n",
            "Predicting....\n",
            "\n",
            "Loaded (4000) images of size (160, 160, 3) in 10.32698130607605 sec.\n",
            "Actual prediction time: 115.27219033241272 sec.\n",
            "Saving...\n",
            "\n",
            "Iteration72 - Images [284000: 288000]\n",
            "Predicting....\n",
            "\n",
            "Loaded (4000) images of size (160, 160, 3) in 10.37725305557251 sec.\n",
            "Actual prediction time: 114.67968225479126 sec.\n",
            "Saving...\n",
            "\n",
            "Iteration73 - Images [288000: 292000]\n",
            "Predicting....\n",
            "\n",
            "Loaded (4000) images of size (160, 160, 3) in 10.456178665161133 sec.\n",
            "Actual prediction time: 115.2012836933136 sec.\n",
            "Saving...\n",
            "\n",
            "Iteration74 - Images [292000: 296000]\n",
            "Predicting....\n",
            "\n",
            "Loaded (4000) images of size (160, 160, 3) in 10.350921869277954 sec.\n",
            "Actual prediction time: 114.5756585597992 sec.\n",
            "Saving...\n",
            "\n",
            "Iteration75 - Images [296000: 300000]\n",
            "Predicting....\n",
            "\n",
            "Loaded (4000) images of size (160, 160, 3) in 10.253956079483032 sec.\n",
            "Actual prediction time: 113.91609358787537 sec.\n",
            "Saving...\n",
            "\n",
            "Iteration76 - Images [300000: 304000]\n",
            "Predicting....\n",
            "\n",
            "Loaded (4000) images of size (160, 160, 3) in 10.1817786693573 sec.\n",
            "Actual prediction time: 113.64794969558716 sec.\n",
            "Saving...\n",
            "\n",
            "Iteration77 - Images [304000: 308000]\n",
            "Predicting....\n",
            "\n",
            "Loaded (4000) images of size (160, 160, 3) in 10.264257431030273 sec.\n",
            "Actual prediction time: 114.37845396995544 sec.\n",
            "Saving...\n",
            "\n",
            "Iteration78 - Images [308000: 312000]\n",
            "Predicting....\n",
            "\n",
            "Loaded (4000) images of size (160, 160, 3) in 10.433672428131104 sec.\n",
            "Actual prediction time: 114.41532015800476 sec.\n",
            "Saving...\n",
            "\n",
            "Iteration79 - Images [312000: 316000]\n",
            "Predicting....\n",
            "\n",
            "Loaded (4000) images of size (160, 160, 3) in 10.262884140014648 sec.\n",
            "Actual prediction time: 114.47701096534729 sec.\n",
            "Saving...\n",
            "\n",
            "Iteration80 - Images [316000: 320000]\n",
            "Predicting....\n",
            "\n",
            "Loaded (4000) images of size (160, 160, 3) in 10.447368383407593 sec.\n",
            "Actual prediction time: 112.92817282676697 sec.\n",
            "Saving...\n",
            "\n",
            "Iteration81 - Images [320000: 324000]\n",
            "Predicting....\n",
            "\n",
            "Loaded (4000) images of size (160, 160, 3) in 10.452232122421265 sec.\n",
            "Actual prediction time: 112.35772919654846 sec.\n",
            "Saving...\n",
            "\n",
            "Iteration82 - Images [324000: 328000]\n",
            "Predicting....\n",
            "\n",
            "Loaded (4000) images of size (160, 160, 3) in 10.351828575134277 sec.\n",
            "Actual prediction time: 114.21068239212036 sec.\n",
            "Saving...\n",
            "\n",
            "Iteration83 - Images [328000: 332000]\n",
            "Predicting....\n",
            "\n",
            "Loaded (4000) images of size (160, 160, 3) in 10.25540542602539 sec.\n",
            "Actual prediction time: 113.96027088165283 sec.\n",
            "Saving...\n",
            "\n",
            "Iteration84 - Images [332000: 336000]\n",
            "Predicting....\n",
            "\n",
            "Loaded (4000) images of size (160, 160, 3) in 10.420751333236694 sec.\n",
            "Actual prediction time: 114.27508306503296 sec.\n",
            "Saving...\n",
            "\n",
            "Iteration85 - Images [336000: 340000]\n",
            "Predicting....\n",
            "\n",
            "Loaded (4000) images of size (160, 160, 3) in 10.52657961845398 sec.\n",
            "Actual prediction time: 116.29279160499573 sec.\n",
            "Saving...\n",
            "\n",
            "Iteration86 - Images [340000: 344000]\n",
            "Predicting....\n",
            "\n",
            "Loaded (4000) images of size (160, 160, 3) in 10.611433506011963 sec.\n",
            "Actual prediction time: 116.62677145004272 sec.\n",
            "Saving...\n",
            "\n",
            "Iteration87 - Images [344000: 348000]\n",
            "Predicting....\n",
            "\n",
            "Loaded (4000) images of size (160, 160, 3) in 10.650830268859863 sec.\n",
            "Actual prediction time: 115.97070407867432 sec.\n",
            "Saving...\n",
            "\n",
            "Iteration88 - Images [348000: 352000]\n",
            "Predicting....\n",
            "\n",
            "Loaded (4000) images of size (160, 160, 3) in 10.323615550994873 sec.\n",
            "Actual prediction time: 115.75769543647766 sec.\n",
            "Saving...\n",
            "\n",
            "Iteration89 - Images [352000: 356000]\n",
            "Predicting....\n",
            "\n",
            "Loaded (4000) images of size (160, 160, 3) in 10.377854108810425 sec.\n",
            "Actual prediction time: 116.26327300071716 sec.\n",
            "Saving...\n",
            "\n",
            "Iteration90 - Images [356000: 360000]\n",
            "Predicting....\n",
            "\n",
            "Loaded (4000) images of size (160, 160, 3) in 10.697219133377075 sec.\n",
            "Actual prediction time: 116.45129752159119 sec.\n",
            "Saving...\n",
            "\n",
            "Iteration91 - Images [360000: 364000]\n",
            "Predicting....\n",
            "\n",
            "Loaded (4000) images of size (160, 160, 3) in 10.542412281036377 sec.\n",
            "Actual prediction time: 115.5662751197815 sec.\n",
            "Saving...\n",
            "\n",
            "Iteration92 - Images [364000: 368000]\n",
            "Predicting....\n",
            "\n",
            "Loaded (4000) images of size (160, 160, 3) in 10.456468343734741 sec.\n",
            "Actual prediction time: 115.46133518218994 sec.\n",
            "Saving...\n",
            "\n",
            "Iteration93 - Images [368000: 372000]\n",
            "Predicting....\n",
            "\n",
            "Loaded (4000) images of size (160, 160, 3) in 10.62421989440918 sec.\n",
            "Actual prediction time: 116.09713864326477 sec.\n",
            "Saving...\n",
            "\n",
            "Iteration94 - Images [372000: 376000]\n",
            "Predicting....\n",
            "\n",
            "Loaded (4000) images of size (160, 160, 3) in 10.553567171096802 sec.\n",
            "Actual prediction time: 116.78963160514832 sec.\n",
            "Saving...\n",
            "\n",
            "Iteration95 - Images [376000: 380000]\n",
            "Predicting....\n",
            "\n",
            "Loaded (4000) images of size (160, 160, 3) in 10.700757265090942 sec.\n",
            "Actual prediction time: 118.16704440116882 sec.\n",
            "Saving...\n",
            "\n",
            "Iteration96 - Images [380000: 384000]\n",
            "Predicting....\n",
            "\n",
            "Loaded (4000) images of size (160, 160, 3) in 10.54041051864624 sec.\n",
            "Actual prediction time: 117.3217306137085 sec.\n",
            "Saving...\n",
            "\n",
            "Iteration97 - Images [384000: 388000]\n",
            "Predicting....\n",
            "\n",
            "Loaded (4000) images of size (160, 160, 3) in 10.540770530700684 sec.\n",
            "Actual prediction time: 117.30110597610474 sec.\n",
            "Saving...\n",
            "\n",
            "Iteration98 - Images [388000: 392000]\n",
            "Predicting....\n",
            "\n",
            "Loaded (4000) images of size (160, 160, 3) in 10.492234945297241 sec.\n",
            "Actual prediction time: 116.12868809700012 sec.\n",
            "Saving...\n",
            "\n",
            "Iteration99 - Images [392000: 396000]\n",
            "Predicting....\n",
            "\n",
            "Loaded (4000) images of size (160, 160, 3) in 10.458621978759766 sec.\n",
            "Actual prediction time: 116.13949155807495 sec.\n",
            "Saving...\n",
            "\n",
            "Iteration100 - Images [396000: 400000]\n",
            "Predicting....\n",
            "\n",
            "Loaded (4000) images of size (160, 160, 3) in 10.46551251411438 sec.\n",
            "Actual prediction time: 116.78550577163696 sec.\n",
            "Saving...\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}